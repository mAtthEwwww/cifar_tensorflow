\relax 
\citation{Glorot2010UnderstandingTD}
\citation{Ioffe2015BatchNA}
\@writefile{toc}{\contentsline {section}{\numberline {1}引言}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}卷积神经网络的图像分类应用}{1}}
\newlabel{predict}{{1}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}网络参数的最大似然估计}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}卷积神经网络}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}卷积层}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}降采样层}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces 最大采样, 采样窗大小为$2\times 2$, 采样步长为$2\times 2$.\relax }}{4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{maxpool}{{1}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}全连接层}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}激活函数}{4}}
\citation{Lecun1998GradientbasedLA}
\citation{Krizhevsky2012ImageNetCW}
\citation{Simonyan2014VeryDC}
\citation{He2016DeepRL}
\citation{He2016IdentityMI}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5}输出层}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces 用于手写数字分类卷积神经网络LeNet5的结构示意图.\relax }}{5}}
\newlabel{lenet}{{2}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}残差网络}{5}}
\citation{Krizhevsky2009LearningML}
\citation{Lin2013NetworkIN}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces (a)是典型的卷积神经网络中的一部分, 信号从浅层到深层逐层传播. (b)是一个残差单元, 信号沿着主路径逐层传播的同时还会通过捷径传播. 深度残差网络通常可以包含数十上百个这样的残差单元.\relax }}{6}}
\newlabel{residual}{{3}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {3}实验}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}CIFAR-10图像数据集}{6}}
\citation{He2015DelvingDI}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}网络结构和训练策略}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces 本文中采用的网络的结构图. 在第一个残差单元中, 在捷径的路径上还设置了一个Batch Normalization层和ReLu层.\relax }}{7}}
\newlabel{resnet}{{4}{7}}
\bibstyle{plain}
\bibdata{YourFile/reference}
\bibcite{Glorot2010UnderstandingTD}{1}
\bibcite{He2015DelvingDI}{2}
\bibcite{He2016DeepRL}{3}
\bibcite{He2016IdentityMI}{4}
\bibcite{Ioffe2015BatchNA}{5}
\bibcite{Krizhevsky2009LearningML}{6}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}结果}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces 随着训练迭代次数增长, 交叉熵损失函数的变化曲线.\relax }}{8}}
\newlabel{loss}{{5}{8}}
\bibcite{Krizhevsky2012ImageNetCW}{7}
\bibcite{Lecun1998GradientbasedLA}{8}
\bibcite{Lin2013NetworkIN}{9}
\bibcite{Simonyan2014VeryDC}{10}
